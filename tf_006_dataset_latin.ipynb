{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:18.878674Z",
     "iopub.status.busy": "2022-11-08T12:18:18.878026Z",
     "iopub.status.idle": "2022-11-08T12:18:21.535258Z",
     "shell.execute_reply": "2022-11-08T12:18:21.534557Z"
    },
    "id": "JjJJyJTZYebt"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-cCvXbPkccV1"
   },
   "source": [
    "# Load the dataset\n",
    "## Vulgar Latin and Italian words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>vulgar_latin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abbacchiare</td>\n",
       "      <td>abbaclare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abbattere</td>\n",
       "      <td>abbatto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abbeverare</td>\n",
       "      <td>abbiberare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abbracciare</td>\n",
       "      <td>adbracchiare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abbrustolire</td>\n",
       "      <td>brustulare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        italian  vulgar_latin\n",
       "0   abbacchiare     abbaclare\n",
       "1     abbattere       abbatto\n",
       "2    abbeverare    abbiberare\n",
       "3   abbracciare  adbracchiare\n",
       "4  abbrustolire    brustulare"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./it-vl-ascii.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutate\n",
    "df = df.sample(len(df))\n",
    "\n",
    "X_final = df.vulgar_latin.values[-10:]\n",
    "y_final = df.italian.values[-10:]\n",
    "\n",
    "lt_ds = df.vulgar_latin.values[:-10]\n",
    "it_ds = df.italian.values[:-10]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(lt_ds, it_ds, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \"\"\"tokenization of words\n",
    "    \"\"\"    \n",
    "    def __init__(self):\n",
    "        self.vocabs = ['[PAD]', '[UNK]', '[START]', '[END]'] + list(string.ascii_lowercase)\n",
    "        range = np.arange(len(self.vocabs))\n",
    "        self.conv_to_id = dict(zip(self.vocabs, range))\n",
    "        self.conv_to_word = dict(zip(range, self.vocabs))\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return len(self.vocabs)\n",
    "\n",
    "    \"\"\" tokenization \"\"\"\n",
    "\n",
    "    def word_to_id(self, word):\n",
    "        if word in self.conv_to_id:\n",
    "            return self.conv_to_id[word]\n",
    "        else:\n",
    "            return self.conv_to_id['[UNK]']\n",
    "\n",
    "    def tokenize_sentence(self, sentence):\n",
    "        tok = [self.word_to_id(word) for word in list(sentence)]\n",
    "        tok = [self.conv_to_id['[START]']] + tok + [self.conv_to_id['[END]']] \n",
    "        return tok\n",
    "\n",
    "    def tokenize_sentences(self, sentences):\n",
    "        tok = [self.tokenize_sentence(sentence) for sentence in sentences]\n",
    "        return tok\n",
    "\n",
    "    \"\"\" detokenization \"\"\"\n",
    "\n",
    "    def id_to_word(self, id):\n",
    "        if id in self.conv_to_word:\n",
    "            return self.conv_to_word[id]\n",
    "        else:\n",
    "            return self.conv_to_word[1] # [UNK]\n",
    "\n",
    "    def detokenize_sentence(self, sentence):\n",
    "        detok = [self.id_to_word(id) for id in sentence]\n",
    "        detok = ''.join(detok)\n",
    "        return detok\n",
    "\n",
    "    def detokenize_sentences(self, sentences):\n",
    "        tok = [self.detokenize_sentence(sentence) for sentence in sentences]\n",
    "        return tok\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 128\n",
    "lttok = Tokenizer()\n",
    "ittok = Tokenizer()\n",
    "\n",
    "def prepare_dataset(lt, it):\n",
    "    \"\"\"prepare the dataset to input to transformer\"\"\" \n",
    "    lt = lttok.tokenize_sentences(lt)  # Output is ragged.\n",
    "    lt = tf.ragged.constant(lt)\n",
    "    lt = lt[:, :MAX_TOKENS]    # Trim to MAX_TOKENS.\n",
    "    lt = lt.to_tensor()  # Convert to 0-padded dense Tensor\n",
    "\n",
    "    it = ittok.tokenize_sentences(it)  # Output is ragged.\n",
    "    it = tf.ragged.constant(it)\n",
    "    it = it[:, :(MAX_TOKENS+1)]\n",
    "    it_inputs = it[:, :-1].to_tensor()  # Drop the [END] tokens\n",
    "    it_labels = it[:, 1:].to_tensor()   # Drop the [START] tokens\n",
    "\n",
    "    return (lt, it_inputs), it_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = prepare_dataset(X_train, y_train)\n",
    "tr_dataset = tf.data.Dataset.from_tensor_slices(tr_dataset)\n",
    "\n",
    "vl_dataset = prepare_dataset(X_test, y_test)\n",
    "vl_dataset = tf.data.Dataset.from_tensor_slices(vl_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:33.205765Z",
     "iopub.status.busy": "2022-11-08T12:18:33.205252Z",
     "iopub.status.idle": "2022-11-08T12:18:33.208260Z",
     "shell.execute_reply": "2022-11-08T12:18:33.207703Z"
    },
    "id": "bcRp7VcQ5m6g"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def make_batches(ds):\n",
    "  return (\n",
    "      ds\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .batch(BATCH_SIZE)\n",
    "      .prefetch(buffer_size=tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:33.219892Z",
     "iopub.status.busy": "2022-11-08T12:18:33.219319Z",
     "iopub.status.idle": "2022-11-08T12:18:33.594226Z",
     "shell.execute_reply": "2022-11-08T12:18:33.593545Z"
    },
    "id": "BSswr5TKvoNM"
   },
   "outputs": [],
   "source": [
    "# Create training and validation set batches.\n",
    "train_batches = make_batches(tr_dataset)\n",
    "val_batches = make_batches(vl_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer methods and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:34.819182Z",
     "iopub.status.busy": "2022-11-08T12:18:34.818945Z",
     "iopub.status.idle": "2022-11-08T12:18:34.823935Z",
     "shell.execute_reply": "2022-11-08T12:18:34.823380Z"
    },
    "id": "1Rz82wEs5biZ"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "  depth = depth/2\n",
    "\n",
    "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "  \n",
    "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "  angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "  pos_encoding = np.concatenate(\n",
    "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "      axis=-1) \n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:36.030476Z",
     "iopub.status.busy": "2022-11-08T12:18:36.030223Z",
     "iopub.status.idle": "2022-11-08T12:18:36.035596Z",
     "shell.execute_reply": "2022-11-08T12:18:36.034889Z"
    },
    "id": "838tmM1cm9cB"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "  def __init__(self, vocab_size, d_model):\n",
    "    super().__init__()\n",
    "    self.d_model = d_model\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True) \n",
    "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "  def compute_mask(self, *args, **kwargs):\n",
    "    return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "  def call(self, x):\n",
    "    length = tf.shape(x)[1]\n",
    "    x = self.embedding(x)\n",
    "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:36.167984Z",
     "iopub.status.busy": "2022-11-08T12:18:36.167745Z",
     "iopub.status.idle": "2022-11-08T12:18:36.171569Z",
     "shell.execute_reply": "2022-11-08T12:18:36.171014Z"
    },
    "id": "5VLa5QcdPpv5"
   },
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:36.175868Z",
     "iopub.status.busy": "2022-11-08T12:18:36.175613Z",
     "iopub.status.idle": "2022-11-08T12:18:36.179853Z",
     "shell.execute_reply": "2022-11-08T12:18:36.179309Z"
    },
    "id": "kfHVbJUWv8qp"
   },
   "outputs": [],
   "source": [
    "class CrossAttention(BaseAttention):\n",
    "  def call(self, x, context):\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        key=context,\n",
    "        value=context,\n",
    "        return_attention_scores=True)\n",
    "   \n",
    "    # Cache the attention scores for plotting later.\n",
    "    self.last_attn_scores = attn_scores\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:36.496021Z",
     "iopub.status.busy": "2022-11-08T12:18:36.495713Z",
     "iopub.status.idle": "2022-11-08T12:18:36.499954Z",
     "shell.execute_reply": "2022-11-08T12:18:36.499373Z"
    },
    "id": "RNqoTpn1wB3i"
   },
   "outputs": [],
   "source": [
    "class GlobalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:36.538366Z",
     "iopub.status.busy": "2022-11-08T12:18:36.538123Z",
     "iopub.status.idle": "2022-11-08T12:18:36.541974Z",
     "shell.execute_reply": "2022-11-08T12:18:36.541412Z"
    },
    "id": "4MMQ-AfKD99_"
   },
   "outputs": [],
   "source": [
    "class CausalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x,\n",
    "        use_causal_mask = True)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:36.619406Z",
     "iopub.status.busy": "2022-11-08T12:18:36.619178Z",
     "iopub.status.idle": "2022-11-08T12:18:36.623982Z",
     "shell.execute_reply": "2022-11-08T12:18:36.623448Z"
    },
    "id": "rAYLeu0uwXYK"
   },
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.seq = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),\n",
    "      tf.keras.layers.Dense(d_model),\n",
    "      tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.add([x, self.seq(x)])\n",
    "    x = self.layer_norm(x) \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:36.680678Z",
     "iopub.status.busy": "2022-11-08T12:18:36.680434Z",
     "iopub.status.idle": "2022-11-08T12:18:36.684729Z",
     "shell.execute_reply": "2022-11-08T12:18:36.684137Z"
    },
    "id": "ncyS-Ms3i2x_"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attention = GlobalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.self_attention(x)\n",
    "    x = self.ffn(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:36.770074Z",
     "iopub.status.busy": "2022-11-08T12:18:36.769842Z",
     "iopub.status.idle": "2022-11-08T12:18:36.775071Z",
     "shell.execute_reply": "2022-11-08T12:18:36.774512Z"
    },
    "id": "jpEox7gJ8FCI"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads,\n",
    "               dff, vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(\n",
    "        vocab_size=vocab_size, d_model=d_model)\n",
    "\n",
    "    self.enc_layers = [\n",
    "        EncoderLayer(d_model=d_model,\n",
    "                     num_heads=num_heads,\n",
    "                     dff=dff,\n",
    "                     dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x):\n",
    "    # `x` is token-IDs shape: (batch, seq_len)\n",
    "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "    \n",
    "    # Add dropout.\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x)\n",
    "\n",
    "    return x  # Shape `(batch_size, seq_len, d_model)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:37.088410Z",
     "iopub.status.busy": "2022-11-08T12:18:37.088158Z",
     "iopub.status.idle": "2022-11-08T12:18:37.093460Z",
     "shell.execute_reply": "2022-11-08T12:18:37.092860Z"
    },
    "id": "9SoX0-vd1hue"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,\n",
    "               *,\n",
    "               d_model,\n",
    "               num_heads,\n",
    "               dff,\n",
    "               dropout_rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.causal_self_attention = CausalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "    \n",
    "    self.cross_attention = CrossAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x, context):\n",
    "    x = self.causal_self_attention(x=x)\n",
    "    x = self.cross_attention(x=x, context=context)\n",
    "\n",
    "    # Cache the last attention scores for plotting later\n",
    "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:37.210068Z",
     "iopub.status.busy": "2022-11-08T12:18:37.209835Z",
     "iopub.status.idle": "2022-11-08T12:18:37.215411Z",
     "shell.execute_reply": "2022-11-08T12:18:37.214857Z"
    },
    "id": "d5_d5-PLQXwY"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
    "               dropout_rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
    "                                             d_model=d_model)\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dec_layers = [\n",
    "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
    "                     dff=dff, dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "\n",
    "    self.last_attn_scores = None\n",
    "\n",
    "  def call(self, x, context):\n",
    "    # `x` is token-IDs shape (batch, target_seq_len)\n",
    "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x  = self.dec_layers[i](x, context)\n",
    "\n",
    "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "\n",
    "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:37.679487Z",
     "iopub.status.busy": "2022-11-08T12:18:37.679241Z",
     "iopub.status.idle": "2022-11-08T12:18:37.684883Z",
     "shell.execute_reply": "2022-11-08T12:18:37.684251Z"
    },
    "id": "PED3bIpOYkBu"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
    "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=input_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=target_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
    "    # first argument.\n",
    "    context, x  = inputs\n",
    "\n",
    "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
    "\n",
    "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
    "\n",
    "    # Final linear layer output.\n",
    "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
    "\n",
    "    try:\n",
    "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
    "      # b/250038731\n",
    "      del logits._keras_mask\n",
    "    except AttributeError:\n",
    "      pass\n",
    "\n",
    "    # Return the final output and the attention weights.\n",
    "    return logits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:37.688494Z",
     "iopub.status.busy": "2022-11-08T12:18:37.688274Z",
     "iopub.status.idle": "2022-11-08T12:18:37.691587Z",
     "shell.execute_reply": "2022-11-08T12:18:37.691045Z"
    },
    "id": "mzyo6KDfVyhl"
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:37.695207Z",
     "iopub.status.busy": "2022-11-08T12:18:37.694972Z",
     "iopub.status.idle": "2022-11-08T12:18:37.773721Z",
     "shell.execute_reply": "2022-11-08T12:18:37.773152Z"
    },
    "id": "UiysUa--4tOU"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=lttok.get_vocab_size(),\n",
    "    target_vocab_size=ittok.get_vocab_size(),\n",
    "    dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:38.506707Z",
     "iopub.status.busy": "2022-11-08T12:18:38.506476Z",
     "iopub.status.idle": "2022-11-08T12:18:38.511214Z",
     "shell.execute_reply": "2022-11-08T12:18:38.510655Z"
    },
    "id": "iYQdOO1axwEI"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:38.514875Z",
     "iopub.status.busy": "2022-11-08T12:18:38.514513Z",
     "iopub.status.idle": "2022-11-08T12:18:38.518189Z",
     "shell.execute_reply": "2022-11-08T12:18:38.517622Z"
    },
    "id": "7r4scdulztRx"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:38.673843Z",
     "iopub.status.busy": "2022-11-08T12:18:38.673256Z",
     "iopub.status.idle": "2022-11-08T12:18:38.678519Z",
     "shell.execute_reply": "2022-11-08T12:18:38.677949Z"
    },
    "id": "67oqVHiT0Eiu"
   },
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "  mask = label != 0\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "  loss = loss_object(label, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss *= mask\n",
    "\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "  return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "  pred = tf.argmax(pred, axis=2)\n",
    "  label = tf.cast(label, pred.dtype)\n",
    "  match = label == pred\n",
    "\n",
    "  mask = label != 0\n",
    "\n",
    "  match = match & mask\n",
    "\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:38.682691Z",
     "iopub.status.busy": "2022-11-08T12:18:38.682244Z",
     "iopub.status.idle": "2022-11-08T12:18:38.694493Z",
     "shell.execute_reply": "2022-11-08T12:18:38.693930Z"
    },
    "id": "Una1v0hDlIsT"
   },
   "outputs": [],
   "source": [
    "transformer.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T12:18:38.697917Z",
     "iopub.status.busy": "2022-11-08T12:18:38.697403Z",
     "iopub.status.idle": "2022-11-08T13:05:03.970830Z",
     "shell.execute_reply": "2022-11-08T13:05:03.969912Z"
    },
    "id": "Jg35qKvVlctp"
   },
   "outputs": [],
   "source": [
    "transformer.fit(train_batches,\n",
    "                epochs=N_EPOCHS,\n",
    "                validation_data=val_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxKpqCbzSW6z"
   },
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T13:05:03.975594Z",
     "iopub.status.busy": "2022-11-08T13:05:03.974978Z",
     "iopub.status.idle": "2022-11-08T13:05:03.984035Z",
     "shell.execute_reply": "2022-11-08T13:05:03.983398Z"
    },
    "id": "eY_uXsOhSmbb"
   },
   "outputs": [],
   "source": [
    "class Translator(tf.Module):\n",
    "  def __init__(self, lttok, ittok, transformer):\n",
    "    self.lttok = lttok\n",
    "    self.ittok = ittok\n",
    "    self.transformer = transformer\n",
    "\n",
    "  def __call__(self, sentence, max_length=MAX_TOKENS):\n",
    "    # The input sentence is Vulgar Latin, hence adding the `[START]` and `[END]` tokens.\n",
    "    # It's done inside tokenize_sentence()\n",
    "\n",
    "    sentence = self.lttok.tokenize_sentence(sentence)\n",
    "    encoder_input = tf.constant(sentence)[tf.newaxis]\n",
    "\n",
    "    # As the output language is Italian, initialize the output with the\n",
    "    # Italian `[START]` token.\n",
    "    start, _, end = self.lttok.tokenize_sentence([''])\n",
    "    start = tf.constant(start, dtype=tf.int64)[tf.newaxis]\n",
    "    end = tf.constant(end, dtype=tf.int64)[tf.newaxis]\n",
    "\n",
    "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
    "    # dynamic-loop can be traced by `tf.function`.\n",
    "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "    output_array = output_array.write(0, start)\n",
    "\n",
    "    for i in tf.range(max_length):\n",
    "      output = tf.transpose(output_array.stack())\n",
    "      predictions = self.transformer([encoder_input, output], training=False)\n",
    "\n",
    "      # Select the last token from the `seq_len` dimension.\n",
    "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
    "\n",
    "      predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "      # Concatenate the `predicted_id` to the output which is given to the\n",
    "      # decoder as its input.\n",
    "      output_array = output_array.write(i+1, predicted_id[0])\n",
    "\n",
    "      if predicted_id == end:\n",
    "        break\n",
    "\n",
    "    output = tf.transpose(output_array.stack())\n",
    "    text = self.ittok.detokenize_sentence(output[0][1:-1].numpy())\n",
    "\n",
    "    # `tf.function` prevents us from using the attention_weights that were\n",
    "    # calculated on the last iteration of the loop.\n",
    "    # So, recalculate them outside the loop.\n",
    "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
    "    attention_weights = self.transformer.decoder.last_attn_scores\n",
    "\n",
    "    return text, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T13:05:03.987727Z",
     "iopub.status.busy": "2022-11-08T13:05:03.987265Z",
     "iopub.status.idle": "2022-11-08T13:05:03.990872Z",
     "shell.execute_reply": "2022-11-08T13:05:03.990102Z"
    },
    "id": "-NjbvpHUTEia"
   },
   "outputs": [],
   "source": [
    "translator = Translator(lttok, ittok, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T13:05:03.994096Z",
     "iopub.status.busy": "2022-11-08T13:05:03.993611Z",
     "iopub.status.idle": "2022-11-08T13:05:03.997587Z",
     "shell.execute_reply": "2022-11-08T13:05:03.996731Z"
    },
    "id": "QfHSRdejTFsC"
   },
   "outputs": [],
   "source": [
    "def print_translation(sentence, tokens, ground_truth):\n",
    "  print(f'{\"Input:\":15s}: {sentence}')\n",
    "  print(f'{\"Prediction\":15s}: {tokens}')\n",
    "  print(f'{\"Ground truth\":15s}: {ground_truth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>prediction</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lusciniolus</td>\n",
       "      <td>loscinolo</td>\n",
       "      <td>lusignolo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jeniperus</td>\n",
       "      <td>genvero</td>\n",
       "      <td>ginepro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>artefacto</td>\n",
       "      <td>arteffare</td>\n",
       "      <td>artefatto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>speclum</td>\n",
       "      <td>specchio</td>\n",
       "      <td>specchio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>torsus</td>\n",
       "      <td>torso</td>\n",
       "      <td>trozza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tiro</td>\n",
       "      <td>tiro</td>\n",
       "      <td>tirare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>manum gemellam</td>\n",
       "      <td>manoglio</td>\n",
       "      <td>giumella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>exseperare</td>\n",
       "      <td>sceverare</td>\n",
       "      <td>sceverare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stantia</td>\n",
       "      <td>stanza</td>\n",
       "      <td>stanza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vela</td>\n",
       "      <td>vela</td>\n",
       "      <td>vela</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            input prediction ground_truth\n",
       "0     lusciniolus  loscinolo    lusignolo\n",
       "1       jeniperus    genvero      ginepro\n",
       "2       artefacto  arteffare    artefatto\n",
       "3         speclum   specchio     specchio\n",
       "4          torsus      torso       trozza\n",
       "5            tiro       tiro       tirare\n",
       "6  manum gemellam   manoglio     giumella\n",
       "7      exseperare  sceverare    sceverare\n",
       "8         stantia     stanza       stanza\n",
       "9            vela       vela         vela"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = [dict(input=X, prediction=translator(X)[0], ground_truth=y) for X, y in zip(X_final, y_final)]\n",
    "df_test_preds = pd.DataFrame(test_preds)\n",
    "df_test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aB_03k0kTQLb"
   },
   "source": [
    "## Create attention plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miZXl9i-TSs6"
   },
   "source": [
    "The `Translator` class you created in the previous section returns a dictionary of attention heatmaps you can use to visualize the internal working of the model.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T13:05:11.094452Z",
     "iopub.status.busy": "2022-11-08T13:05:11.093801Z",
     "iopub.status.idle": "2022-11-08T13:05:12.644010Z",
     "shell.execute_reply": "2022-11-08T13:05:12.643199Z"
    },
    "id": "V3m2wcNLTU8K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:         : speclum\n",
      "Prediction     : specchio\n",
      "Ground truth   : specchio\n"
     ]
    }
   ],
   "source": [
    "sentence = 'speclum'\n",
    "ground_truth = \"specchio\"\n",
    "\n",
    "translated_text, attention_weights = translator(sentence)\n",
    "print_translation(sentence, translated_text, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rhE_LW7TZ40"
   },
   "source": [
    "Create a function that plots the attention when a token is generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T13:05:12.648070Z",
     "iopub.status.busy": "2022-11-08T13:05:12.647491Z",
     "iopub.status.idle": "2022-11-08T13:05:12.652351Z",
     "shell.execute_reply": "2022-11-08T13:05:12.651580Z"
    },
    "id": "gKlxYO0JTXzD"
   },
   "outputs": [],
   "source": [
    "def plot_attention_head(in_tokens, translated_tokens, attention):\n",
    "  # The model didn't generate `<START>` in the output. Skip it.\n",
    "  translated_tokens = translated_tokens[1:]\n",
    "\n",
    "  ax = plt.gca()\n",
    "  ax.matshow(attention)\n",
    "  ax.set_xticks(range(len(in_tokens)))\n",
    "  ax.set_yticks(range(len(translated_tokens)))\n",
    "\n",
    "  labels = [label for label in in_tokens]\n",
    "  ax.set_xticklabels(\n",
    "      labels, rotation=90)\n",
    "\n",
    "  labels = [label for label in translated_tokens]\n",
    "  ax.set_yticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T13:05:12.655792Z",
     "iopub.status.busy": "2022-11-08T13:05:12.655247Z",
     "iopub.status.idle": "2022-11-08T13:05:12.661091Z",
     "shell.execute_reply": "2022-11-08T13:05:12.660408Z"
    },
    "id": "yI4YWU2uXDeW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([9, 9])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = 0\n",
    "# Shape: `(batch=1, num_heads, seq_len_q, seq_len_k)`.\n",
    "attention_heads = tf.squeeze(attention_weights, 0)\n",
    "attention = attention_heads[head]\n",
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T13:05:12.695938Z",
     "iopub.status.busy": "2022-11-08T13:05:12.695421Z",
     "iopub.status.idle": "2022-11-08T13:05:12.893919Z",
     "shell.execute_reply": "2022-11-08T13:05:12.893357Z"
    },
    "id": "lrNh47D1ToBD"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "in_tokens = ['[START]'] + list('speclum') + ['[END]']\n",
    "translated_tokens =  ['[START]'] + list('specchio') + ['[END]']\n",
    "\n",
    "plot_attention_head(in_tokens, translated_tokens, attention)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
    "kind": "private"
   },
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "94988515af8fb6d1dcb18e9f77039815983c9c7f98d31fa872bad79ec3eb4814"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
